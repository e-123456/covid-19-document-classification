{"pmid":32396075,"title":"Deep Learning COVID-19 Features on CXR using Limited Training Data Sets.","text":["Deep Learning COVID-19 Features on CXR using Limited Training Data Sets.","Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage.","IEEE Trans Med Imaging","Oh, Yujin","Park, Sangjoon","Ye, Jong Chul","32396075"],"abstract":["Under the global pandemic of COVID-19, the use of artificial intelligence to analyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is becoming important. Unfortunately, due to the emergent nature of the COVID-19 pandemic, a systematic collection of CXR data set for deep neural network training is difficult. To address this problem, here we propose a patch-based convolutional neural network approach with a relatively small number of trainable parameters for COVID-19 diagnosis. The proposed method is inspired by our statistical analysis of the potential imaging biomarkers of the CXR radiographs. Experimental results show that our method achieves state-of-the-art performance and provides clinically interpretable saliency maps, which are useful for COVID-19 diagnosis and patient triage."],"journal":"IEEE Trans Med Imaging","authors":["Oh, Yujin","Park, Sangjoon","Ye, Jong Chul"],"date":"2020-05-13T11:00:00Z","year":2020,"_id":"32396075","source":"PubMed","week":"202020|May 11 - May 17","doi":"10.1109/TMI.2020.2993291","topics":["Diagnosis"],"weight":1,"_version_":1666627828012023808,"score":9.490897,"similar":[{"pmid":32486140,"title":"Weakly Labeled Data Augmentation for Deep Learning: A Study on COVID-19 Detection in Chest X-Rays.","text":["Weakly Labeled Data Augmentation for Deep Learning: A Study on COVID-19 Detection in Chest X-Rays.","The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a pandemic resulting in over 2.7 million infected individuals and over 190,000 deaths and growing. Assertions in the literature suggest that respiratory disorders due to COVID-19 commonly present with pneumonia-like symptoms which are radiologically confirmed as opacities. Radiology serves as an adjunct to the reverse transcription-polymerase chain reaction test for confirmation and evaluating disease progression. While computed tomography (CT) imaging is more specific than chest X-rays (CXR), its use is limited due to cross-contamination concerns. CXR imaging is commonly used in high-demand situations, placing a significant burden on radiology services. The use of artificial intelligence (AI) has been suggested to alleviate this burden. However, there is a dearth of sufficient training data for developing image-based AI tools. We propose increasing training data for recognizing COVID-19 pneumonia opacities using weakly labeled data augmentation. This follows from a hypothesis that the COVID-19 manifestation would be similar to that caused by other viral pathogens affecting the lungs. We expand the training data distribution for supervised learning through the use of weakly labeled CXR images, automatically pooled from publicly available pneumonia datasets, to classify them into those with bacterial or viral pneumonia opacities. Next, we use these selected images in a stage-wise, strategic approach to train convolutional neural network-based algorithms and compare against those trained with non-augmented data. Weakly labeled data augmentation expands the learned feature space in an attempt to encompass variability in unseen test distributions, enhance inter-class discrimination, and reduce the generalization error. Empirical evaluations demonstrate that simple weakly labeled data augmentation (Acc: 0.5555 and Acc: 0.6536) is better than baseline non-augmented training (Acc: 0.2885 and Acc: 0.5028) in identifying COVID-19 manifestations as viral pneumonia. Interestingly, adding COVID-19 CXRs to simple weakly labeled augmented training data significantly improves the performance (Acc: 0.7095 and Acc: 0.8889), suggesting that COVID-19, though viral in origin, creates a uniquely different presentation in CXRs compared with other viral pneumonia manifestations.","Diagnostics (Basel)","Rajaraman, Sivaramakrishnan","Antani, Sameer","32486140"],"abstract":["The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a pandemic resulting in over 2.7 million infected individuals and over 190,000 deaths and growing. Assertions in the literature suggest that respiratory disorders due to COVID-19 commonly present with pneumonia-like symptoms which are radiologically confirmed as opacities. Radiology serves as an adjunct to the reverse transcription-polymerase chain reaction test for confirmation and evaluating disease progression. While computed tomography (CT) imaging is more specific than chest X-rays (CXR), its use is limited due to cross-contamination concerns. CXR imaging is commonly used in high-demand situations, placing a significant burden on radiology services. The use of artificial intelligence (AI) has been suggested to alleviate this burden. However, there is a dearth of sufficient training data for developing image-based AI tools. We propose increasing training data for recognizing COVID-19 pneumonia opacities using weakly labeled data augmentation. This follows from a hypothesis that the COVID-19 manifestation would be similar to that caused by other viral pathogens affecting the lungs. We expand the training data distribution for supervised learning through the use of weakly labeled CXR images, automatically pooled from publicly available pneumonia datasets, to classify them into those with bacterial or viral pneumonia opacities. Next, we use these selected images in a stage-wise, strategic approach to train convolutional neural network-based algorithms and compare against those trained with non-augmented data. Weakly labeled data augmentation expands the learned feature space in an attempt to encompass variability in unseen test distributions, enhance inter-class discrimination, and reduce the generalization error. Empirical evaluations demonstrate that simple weakly labeled data augmentation (Acc: 0.5555 and Acc: 0.6536) is better than baseline non-augmented training (Acc: 0.2885 and Acc: 0.5028) in identifying COVID-19 manifestations as viral pneumonia. Interestingly, adding COVID-19 CXRs to simple weakly labeled augmented training data significantly improves the performance (Acc: 0.7095 and Acc: 0.8889), suggesting that COVID-19, though viral in origin, creates a uniquely different presentation in CXRs compared with other viral pneumonia manifestations."],"journal":"Diagnostics (Basel)","authors":["Rajaraman, Sivaramakrishnan","Antani, Sameer"],"date":"2020-06-04T11:00:00Z","year":2020,"_id":"32486140","source":"PubMed","week":"202023|Jun 01 - Jun 07","doi":"10.3390/diagnostics10060358","keywords":["covid-19","augmentation","chest x-rays","convolutional neural network","deep learning","localization","pneumonia"],"topics":["Diagnosis"],"weight":1,"_version_":1668892169432203264,"score":251.86761},{"pmid":32412551,"pmcid":"PMC7221329","title":"Extracting Possibly Representative COVID-19 Biomarkers from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary Diseases.","text":["Extracting Possibly Representative COVID-19 Biomarkers from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary Diseases.","Purpose: While the spread of COVID-19 is increased, new, automatic, and reliable methods for accurate detection are essential to reduce the exposure of the medical experts to the outbreak. X-ray imaging, although limited to specific visualizations, may be helpful for the diagnosis. In this study, the problem of automatic classification of pulmonary diseases, including the recently emerged COVID-19, from X-ray images, is considered. Methods: Deep Learning has proven to be a remarkable method to extract massive high-dimensional features from medical images. Specifically, in this paper, the state-of-the-art Convolutional Neural Network called Mobile Net is employed and trained from scratch to investigate the importance of the extracted features for the classification task. A large-scale dataset of 3905 X-ray images, corresponding to 6 diseases, is utilized for training MobileNet v2, which has been proven to achieve excellent results in related tasks. Results: Training the CNNs from scratch outperforms the other transfer learning techniques, both in distinguishing the X-rays between the seven classes and between Covid-19 and non-Covid-19. A classification accuracy between the seven classes of 87.66% is achieved. Besides, this method achieves 99.18% accuracy, 97.36% Sensitivity, and 99.42% Specificity in the detection of COVID-19. Conclusion: The results suggest that training CNNs from scratch may reveal vital biomarkers related but not limited to the COVID-19 disease, while the top classification accuracy suggests further examination of the X-ray imaging potential.","J Med Biol Eng","Apostolopoulos, Ioannis D","Aznaouridis, Sokratis I","Tzani, Mpesiana A","32412551"],"abstract":["Purpose: While the spread of COVID-19 is increased, new, automatic, and reliable methods for accurate detection are essential to reduce the exposure of the medical experts to the outbreak. X-ray imaging, although limited to specific visualizations, may be helpful for the diagnosis. In this study, the problem of automatic classification of pulmonary diseases, including the recently emerged COVID-19, from X-ray images, is considered. Methods: Deep Learning has proven to be a remarkable method to extract massive high-dimensional features from medical images. Specifically, in this paper, the state-of-the-art Convolutional Neural Network called Mobile Net is employed and trained from scratch to investigate the importance of the extracted features for the classification task. A large-scale dataset of 3905 X-ray images, corresponding to 6 diseases, is utilized for training MobileNet v2, which has been proven to achieve excellent results in related tasks. Results: Training the CNNs from scratch outperforms the other transfer learning techniques, both in distinguishing the X-rays between the seven classes and between Covid-19 and non-Covid-19. A classification accuracy between the seven classes of 87.66% is achieved. Besides, this method achieves 99.18% accuracy, 97.36% Sensitivity, and 99.42% Specificity in the detection of COVID-19. Conclusion: The results suggest that training CNNs from scratch may reveal vital biomarkers related but not limited to the COVID-19 disease, while the top classification accuracy suggests further examination of the X-ray imaging potential."],"journal":"J Med Biol Eng","authors":["Apostolopoulos, Ioannis D","Aznaouridis, Sokratis I","Tzani, Mpesiana A"],"date":"2020-05-16T11:00:00Z","year":2020,"_id":"32412551","source":"PubMed","week":"202020|May 11 - May 17","doi":"10.1007/s40846-020-00529-4","keywords":["biomarkers","covid-19","deep learning","pulmonary disease detection","training from scratch","x-ray imaging"],"topics":["Diagnosis"],"weight":1,"_version_":1666897319244595201,"score":217.54443},{"pmid":32462314,"title":"Deep learning COVID-19 detection bias: accuracy through artificial intelligence.","text":["Deep learning COVID-19 detection bias: accuracy through artificial intelligence.","BACKGROUND: Detection of COVID-19 cases' accuracy is posing a conundrum for scientists, physicians, and policy-makers. As of April 23, 2020, 2.7 million cases have been confirmed, over 190,000 people are dead, and about 750,000 people are reported recovered. Yet, there is no publicly available data on tests that could be missing infections. Complicating matters and furthering anxiety are specific instances of false-negative tests. METHODS: We developed a deep learning model to improve accuracy of reported cases and to precisely predict the disease from chest X-ray scans. Our model relied on convolutional neural networks (CNNs) to detect structural abnormalities and disease categorization that were keys to uncovering hidden patterns. To do so, a transfer learning approach was deployed to perform detections from the chest anterior-posterior radiographs of patients. We used publicly available datasets to achieve this. RESULTS: Our results offer very high accuracy (96.3%) and loss (0.151 binary cross-entropy) using the public dataset consisting of patients from different countries worldwide. As the confusion matrix indicates, our model is able to accurately identify true negatives (74) and true positives (32); this deep learning model identified three cases of false-positive and one false-negative finding from the healthy patient scans. CONCLUSIONS: Our COVID-19 detection model minimizes manual interaction dependent on radiologists as it automates identification of structural abnormalities in patient's CXRs, and our deep learning model is likely to detect true positives and true negatives and weed out false positive and false negatives with > 96.3% accuracy.","Int Orthop","Vaid, Shashank","Kalantar, Reza","Bhandari, Mohit","32462314"],"abstract":["BACKGROUND: Detection of COVID-19 cases' accuracy is posing a conundrum for scientists, physicians, and policy-makers. As of April 23, 2020, 2.7 million cases have been confirmed, over 190,000 people are dead, and about 750,000 people are reported recovered. Yet, there is no publicly available data on tests that could be missing infections. Complicating matters and furthering anxiety are specific instances of false-negative tests. METHODS: We developed a deep learning model to improve accuracy of reported cases and to precisely predict the disease from chest X-ray scans. Our model relied on convolutional neural networks (CNNs) to detect structural abnormalities and disease categorization that were keys to uncovering hidden patterns. To do so, a transfer learning approach was deployed to perform detections from the chest anterior-posterior radiographs of patients. We used publicly available datasets to achieve this. RESULTS: Our results offer very high accuracy (96.3%) and loss (0.151 binary cross-entropy) using the public dataset consisting of patients from different countries worldwide. As the confusion matrix indicates, our model is able to accurately identify true negatives (74) and true positives (32); this deep learning model identified three cases of false-positive and one false-negative finding from the healthy patient scans. CONCLUSIONS: Our COVID-19 detection model minimizes manual interaction dependent on radiologists as it automates identification of structural abnormalities in patient's CXRs, and our deep learning model is likely to detect true positives and true negatives and weed out false positive and false negatives with > 96.3% accuracy."],"journal":"Int Orthop","authors":["Vaid, Shashank","Kalantar, Reza","Bhandari, Mohit"],"date":"2020-05-29T11:00:00Z","year":2020,"_id":"32462314","source":"PubMed","week":"202022|May 25 - May 31","doi":"10.1007/s00264-020-04609-7","keywords":["artificial intelligence","covid-19","deep learning","detection bias"],"topics":["Diagnosis"],"weight":1,"_version_":1668079521545322496,"score":198.79622},{"pmid":32501424,"pmcid":"PMC7255267","title":"A modified deep convolutional neural network for detecting COVID-19 and pneumonia from chest X-ray images based on the concatenation of Xception and ResNet50V2.","text":["A modified deep convolutional neural network for detecting COVID-19 and pneumonia from chest X-ray images based on the concatenation of Xception and ResNet50V2.","In this paper, we have trained several deep convolutional networks with introduced training techniques for classifying X-ray images into three classes: normal, pneumonia, and COVID-19, based on two open-source datasets. Our data contains 180 X-ray images that belong to persons infected with COVID-19, and we attempted to apply methods to achieve the best possible results. In this research, we introduce some training techniques that help the network learn better when we have an unbalanced dataset (fewer cases of COVID-19 along with more cases from other classes). We also propose a neural network that is a concatenation of the Xception and ResNet50V2 networks. This network achieved the best accuracy by utilizing multiple features extracted by two robust networks. For evaluating our network, we have tested it on 11302 images to report the actual accuracy achievable in real circumstances. The average accuracy of the proposed network for detecting COVID-19 cases is 99.50%, and the overall average accuracy for all classes is 91.4%.","Inform Med Unlocked","Rahimzadeh, Mohammad","Attar, Abolfazl","32501424"],"abstract":["In this paper, we have trained several deep convolutional networks with introduced training techniques for classifying X-ray images into three classes: normal, pneumonia, and COVID-19, based on two open-source datasets. Our data contains 180 X-ray images that belong to persons infected with COVID-19, and we attempted to apply methods to achieve the best possible results. In this research, we introduce some training techniques that help the network learn better when we have an unbalanced dataset (fewer cases of COVID-19 along with more cases from other classes). We also propose a neural network that is a concatenation of the Xception and ResNet50V2 networks. This network achieved the best accuracy by utilizing multiple features extracted by two robust networks. For evaluating our network, we have tested it on 11302 images to report the actual accuracy achievable in real circumstances. The average accuracy of the proposed network for detecting COVID-19 cases is 99.50%, and the overall average accuracy for all classes is 91.4%."],"journal":"Inform Med Unlocked","authors":["Rahimzadeh, Mohammad","Attar, Abolfazl"],"date":"2020-06-06T11:00:00Z","year":2020,"_id":"32501424","source":"PubMed","week":"202023|Jun 01 - Jun 07","doi":"10.1016/j.imu.2020.100360","keywords":["covid-19","chest x-ray images","convolutional neural networks","coronavirus","deep feature extraction","deep learning","transfer learning"],"topics":["Diagnosis"],"weight":1,"_version_":1668804508942073857,"score":198.51021},{"pmid":32384019,"title":"COVID-19 on the Chest Radiograph: A Multi-Reader Evaluation of an AI System.","text":["COVID-19 on the Chest Radiograph: A Multi-Reader Evaluation of an AI System.","Background Chest radiography (CXR) may play an important role in triage for COVID-19, particularly in low-resource settings. Purpose To evaluate the performance of an artificial intelligence (AI) system for detection of COVID-19 pneumonia on chest radiographs. Methods An AI system (CAD4COVID-Xray) was trained on 24,678 CXR images including 1,540 used only for validation while training. The test set consisted of a set of continuously acquired CXR images (n=454) obtained in patients suspected for COVID-19 pneumonia between March 4th and April 6th 2020 in a single center (223 RT-PCR positive subjects, 231 RT-PCR negative subjects). The radiographs were independently analyzed by six readers and by the AI system. Diagnostic performance was performed by receiver operating characteristic curve analysis. Results For the test set, the mean age of the patients was 67.3 (+/-14.4) years (56% male). Using RT-PCR test results as the reference standard, the AI system correctly classified CXR images as COVID-19 pneumonia with an AUC of 0.81. The system significantly outperforms each reader (p < 0.001 using McNemar test) at their highest possible sensitivities. At their lowest sensitivities, only one reader can significantly outperform the AI system (p=0.04). Conclusions An AI system for detection of COVID-19 on chest radiographs was comparable to six independent readers.","Radiology","Murphy, Keelin","Smits, Henk","Knoops, Arnoud J G","Korst, Mike B J M","Samson, Tijs","Scholten, Ernst T","Schalekamp, Steven","Schaefer-Prokop, Cornelia M","Philipsen, Rick H H M","Meijers, Annet","Melendez, Jaime","van Ginneken, Bram","Rutten, Matthieu","32384019"],"abstract":["Background Chest radiography (CXR) may play an important role in triage for COVID-19, particularly in low-resource settings. Purpose To evaluate the performance of an artificial intelligence (AI) system for detection of COVID-19 pneumonia on chest radiographs. Methods An AI system (CAD4COVID-Xray) was trained on 24,678 CXR images including 1,540 used only for validation while training. The test set consisted of a set of continuously acquired CXR images (n=454) obtained in patients suspected for COVID-19 pneumonia between March 4th and April 6th 2020 in a single center (223 RT-PCR positive subjects, 231 RT-PCR negative subjects). The radiographs were independently analyzed by six readers and by the AI system. Diagnostic performance was performed by receiver operating characteristic curve analysis. Results For the test set, the mean age of the patients was 67.3 (+/-14.4) years (56% male). Using RT-PCR test results as the reference standard, the AI system correctly classified CXR images as COVID-19 pneumonia with an AUC of 0.81. The system significantly outperforms each reader (p < 0.001 using McNemar test) at their highest possible sensitivities. At their lowest sensitivities, only one reader can significantly outperform the AI system (p=0.04). Conclusions An AI system for detection of COVID-19 on chest radiographs was comparable to six independent readers."],"journal":"Radiology","authors":["Murphy, Keelin","Smits, Henk","Knoops, Arnoud J G","Korst, Mike B J M","Samson, Tijs","Scholten, Ernst T","Schalekamp, Steven","Schaefer-Prokop, Cornelia M","Philipsen, Rick H H M","Meijers, Annet","Melendez, Jaime","van Ginneken, Bram","Rutten, Matthieu"],"date":"2020-05-09T11:00:00Z","year":2020,"_id":"32384019","source":"PubMed","week":"202019|May 04 - May 10","doi":"10.1148/radiol.2020201874","topics":["Diagnosis"],"weight":1,"_version_":1666419683321970688,"score":198.37636}]}