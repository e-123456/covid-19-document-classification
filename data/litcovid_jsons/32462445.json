{"pmid":32462445,"title":"Any unique image biomarkers associated with COVID-19?","text":["Any unique image biomarkers associated with COVID-19?","OBJECTIVE: To define the uniqueness of chest CT infiltrative features associated with COVID-19 image characteristics as potential diagnostic biomarkers. METHODS: We retrospectively collected chest CT exams including n = 498 on 151 unique patients RT-PCR positive for COVID-19 and n = 497 unique patients with community-acquired pneumonia (CAP). Both COVID-19 and CAP image sets were partitioned into three groups for training, validation, and testing respectively. In an attempt to discriminate COVID-19 from CAP, we developed several classifiers based on three-dimensional (3D) convolutional neural networks (CNNs). We also asked two experienced radiologists to visually interpret the testing set and discriminate COVID-19 from CAP. The classification performance of the computer algorithms and the radiologists was assessed using the receiver operating characteristic (ROC) analysis, and the nonparametric approaches with multiplicity adjustments when necessary. RESULTS: One of the considered models showed non-trivial, but moderate diagnostic ability overall (AUC of 0.70 with 99% CI 0.56-0.85). This model allowed for the identification of 8-50% of CAP patients with only 2% of COVID-19 patients. CONCLUSIONS: Professional or automated interpretation of CT exams has a moderately low ability to distinguish between COVID-19 and CAP cases. However, the automated image analysis is promising for targeted decision-making due to being able to accurately identify a sizable subsect of non-COVID-19 cases. KEY POINTS: * Both human experts and artificial intelligent models were used to classify the CT scans. * ROC analysis and the nonparametric approaches were used to analyze the performance of the radiologists and computer algorithms. * Unique image features or patterns may not exist for reliably distinguishing all COVID-19 from CAP; however, there may be imaging markers that can identify a sizable subset of non-COVID-19 cases.","Eur Radiol","Pu, Jiantao","Leader, Joseph","Bandos, Andriy","Shi, Junli","Du, Pang","Yu, Juezhao","Yang, Bohan","Ke, Shi","Guo, Youmin","Field, Jessica B","Fuhrman, Carl","Wilson, David","Sciurba, Frank","Jin, Chenwang","32462445"],"abstract":["OBJECTIVE: To define the uniqueness of chest CT infiltrative features associated with COVID-19 image characteristics as potential diagnostic biomarkers. METHODS: We retrospectively collected chest CT exams including n = 498 on 151 unique patients RT-PCR positive for COVID-19 and n = 497 unique patients with community-acquired pneumonia (CAP). Both COVID-19 and CAP image sets were partitioned into three groups for training, validation, and testing respectively. In an attempt to discriminate COVID-19 from CAP, we developed several classifiers based on three-dimensional (3D) convolutional neural networks (CNNs). We also asked two experienced radiologists to visually interpret the testing set and discriminate COVID-19 from CAP. The classification performance of the computer algorithms and the radiologists was assessed using the receiver operating characteristic (ROC) analysis, and the nonparametric approaches with multiplicity adjustments when necessary. RESULTS: One of the considered models showed non-trivial, but moderate diagnostic ability overall (AUC of 0.70 with 99% CI 0.56-0.85). This model allowed for the identification of 8-50% of CAP patients with only 2% of COVID-19 patients. CONCLUSIONS: Professional or automated interpretation of CT exams has a moderately low ability to distinguish between COVID-19 and CAP cases. However, the automated image analysis is promising for targeted decision-making due to being able to accurately identify a sizable subsect of non-COVID-19 cases. KEY POINTS: * Both human experts and artificial intelligent models were used to classify the CT scans. * ROC analysis and the nonparametric approaches were used to analyze the performance of the radiologists and computer algorithms. * Unique image features or patterns may not exist for reliably distinguishing all COVID-19 from CAP; however, there may be imaging markers that can identify a sizable subset of non-COVID-19 cases."],"journal":"Eur Radiol","authors":["Pu, Jiantao","Leader, Joseph","Bandos, Andriy","Shi, Junli","Du, Pang","Yu, Juezhao","Yang, Bohan","Ke, Shi","Guo, Youmin","Field, Jessica B","Fuhrman, Carl","Wilson, David","Sciurba, Frank","Jin, Chenwang"],"date":"2020-05-29T11:00:00Z","year":2020,"_id":"32462445","source":"PubMed","week":"202022|May 25 - May 31","doi":"10.1007/s00330-020-06956-w","keywords":["biomarkers","covid-19","neural network","pneumonia"],"topics":["Diagnosis"],"weight":1,"_version_":1668079521521205250,"score":9.490897,"similar":[{"pmid":32191588,"title":"Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT.","text":["Artificial Intelligence Distinguishes COVID-19 from Community Acquired Pneumonia on Chest CT.","Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49+/-15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases.","Radiology","Li, Lin","Qin, Lixin","Xu, Zeguo","Yin, Youbing","Wang, Xin","Kong, Bin","Bai, Junjie","Lu, Yi","Fang, Zhenghan","Song, Qi","Cao, Kunlin","Liu, Daliang","Wang, Guisheng","Xu, Qizhong","Fang, Xisheng","Zhang, Shiqin","Xia, Juan","Xia, Jun","32191588"],"abstract":["Background Coronavirus disease has widely spread all over the world since the beginning of 2020. It is desirable to develop automatic and accurate detection of COVID-19 using chest CT. Purpose To develop a fully automatic framework to detect COVID-19 using chest CT and evaluate its performances. Materials and Methods In this retrospective and multi-center study, a deep learning model, COVID-19 detection neural network (COVNet), was developed to extract visual features from volumetric chest CT exams for the detection of COVID-19. Community acquired pneumonia (CAP) and other non-pneumonia CT exams were included to test the robustness of the model. The datasets were collected from 6 hospitals between August 2016 and February 2020. Diagnostic performance was assessed by the area under the receiver operating characteristic curve (AUC), sensitivity and specificity. Results The collected dataset consisted of 4356 chest CT exams from 3,322 patients. The average age is 49+/-15 years and there were slightly more male patients than female (1838 vs 1484; p-value=0.29). The per-exam sensitivity and specificity for detecting COVID-19 in the independent test set was 114 of 127 (90% [95% CI: 83%, 94%]) and 294 of 307 (96% [95% CI: 93%, 98%]), respectively, with an AUC of 0.96 (p-value<0.001). The per-exam sensitivity and specificity for detecting CAP in the independent test set was 87% (152 of 175) and 92% (239 of 259), respectively, with an AUC of 0.95 (95% CI: 0.93, 0.97). Conclusions A deep learning model can accurately detect COVID-19 and differentiate it from community acquired pneumonia and other lung diseases."],"journal":"Radiology","authors":["Li, Lin","Qin, Lixin","Xu, Zeguo","Yin, Youbing","Wang, Xin","Kong, Bin","Bai, Junjie","Lu, Yi","Fang, Zhenghan","Song, Qi","Cao, Kunlin","Liu, Daliang","Wang, Guisheng","Xu, Qizhong","Fang, Xisheng","Zhang, Shiqin","Xia, Juan","Xia, Jun"],"date":"2020-03-20T11:00:00Z","year":2020,"_id":"32191588","source":"PubMed","week":"202012|Mar 16 - Mar 22","doi":"10.1148/radiol.2020200905","topics":["Diagnosis"],"weight":1,"_version_":1666138492505161728,"score":368.9703},{"pmid":32412551,"pmcid":"PMC7221329","title":"Extracting Possibly Representative COVID-19 Biomarkers from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary Diseases.","text":["Extracting Possibly Representative COVID-19 Biomarkers from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary Diseases.","Purpose: While the spread of COVID-19 is increased, new, automatic, and reliable methods for accurate detection are essential to reduce the exposure of the medical experts to the outbreak. X-ray imaging, although limited to specific visualizations, may be helpful for the diagnosis. In this study, the problem of automatic classification of pulmonary diseases, including the recently emerged COVID-19, from X-ray images, is considered. Methods: Deep Learning has proven to be a remarkable method to extract massive high-dimensional features from medical images. Specifically, in this paper, the state-of-the-art Convolutional Neural Network called Mobile Net is employed and trained from scratch to investigate the importance of the extracted features for the classification task. A large-scale dataset of 3905 X-ray images, corresponding to 6 diseases, is utilized for training MobileNet v2, which has been proven to achieve excellent results in related tasks. Results: Training the CNNs from scratch outperforms the other transfer learning techniques, both in distinguishing the X-rays between the seven classes and between Covid-19 and non-Covid-19. A classification accuracy between the seven classes of 87.66% is achieved. Besides, this method achieves 99.18% accuracy, 97.36% Sensitivity, and 99.42% Specificity in the detection of COVID-19. Conclusion: The results suggest that training CNNs from scratch may reveal vital biomarkers related but not limited to the COVID-19 disease, while the top classification accuracy suggests further examination of the X-ray imaging potential.","J Med Biol Eng","Apostolopoulos, Ioannis D","Aznaouridis, Sokratis I","Tzani, Mpesiana A","32412551"],"abstract":["Purpose: While the spread of COVID-19 is increased, new, automatic, and reliable methods for accurate detection are essential to reduce the exposure of the medical experts to the outbreak. X-ray imaging, although limited to specific visualizations, may be helpful for the diagnosis. In this study, the problem of automatic classification of pulmonary diseases, including the recently emerged COVID-19, from X-ray images, is considered. Methods: Deep Learning has proven to be a remarkable method to extract massive high-dimensional features from medical images. Specifically, in this paper, the state-of-the-art Convolutional Neural Network called Mobile Net is employed and trained from scratch to investigate the importance of the extracted features for the classification task. A large-scale dataset of 3905 X-ray images, corresponding to 6 diseases, is utilized for training MobileNet v2, which has been proven to achieve excellent results in related tasks. Results: Training the CNNs from scratch outperforms the other transfer learning techniques, both in distinguishing the X-rays between the seven classes and between Covid-19 and non-Covid-19. A classification accuracy between the seven classes of 87.66% is achieved. Besides, this method achieves 99.18% accuracy, 97.36% Sensitivity, and 99.42% Specificity in the detection of COVID-19. Conclusion: The results suggest that training CNNs from scratch may reveal vital biomarkers related but not limited to the COVID-19 disease, while the top classification accuracy suggests further examination of the X-ray imaging potential."],"journal":"J Med Biol Eng","authors":["Apostolopoulos, Ioannis D","Aznaouridis, Sokratis I","Tzani, Mpesiana A"],"date":"2020-05-16T11:00:00Z","year":2020,"_id":"32412551","source":"PubMed","week":"202020|May 11 - May 17","doi":"10.1007/s40846-020-00529-4","keywords":["biomarkers","covid-19","deep learning","pulmonary disease detection","training from scratch","x-ray imaging"],"topics":["Diagnosis"],"weight":1,"_version_":1666897319244595201,"score":288.94458},{"pmid":32395494,"pmcid":"PMC7210135","title":"Deep learning for detecting corona virus disease 2019 (COVID-19) on high-resolution computed tomography: a pilot study.","text":["Deep learning for detecting corona virus disease 2019 (COVID-19) on high-resolution computed tomography: a pilot study.","Background: To evaluate the diagnostic efficacy of Densely Connected Convolutional Networks (DenseNet) for detection of COVID-19 features on high resolution computed tomography (HRCT). Methods: The Ethic Committee of our institution approved the protocol of this study and waived the requirement for patient informed consent. Two hundreds and ninety-five patients were enrolled in this study (healthy person: 149; COVID-19 patients: 146), which were divided into three separate non-overlapping cohorts (training set, n=135, healthy person, n=69, patients, n=66; validation set, n=20, healthy person, n=10, patients, n=10; test set, n=140, healthy person, n=70, patients, n=70). The DenseNet was trained and tested to classify the images as having manifestation of COVID-19 or as healthy. A radiologist also blindly evaluated all the test images and rechecked the misdiagnosed cases by DenseNet. Receiver operating characteristic curves (ROC) and areas under the curve (AUCs) were used to assess the model performance. The sensitivity, specificity and accuracy of DenseNet model and radiologist were also calculated. Results: The DenseNet algorithm model yielded an AUC of 0.99 (95% CI: 0.958-1.0) in the validation set and 0.98 (95% CI: 0.972-0.995) in the test set. The threshold value was selected as 0.8, while for validation and test sets, the accuracies were 95% and 92%, the sensitivities were 100% and 97%, the specificities were 90% and 87%, and the F1 values were 95% and 93%, respectively. The sensitivity of radiologist was 94%, the specificity was 96%, while the accuracy was 95%. Conclusions: Deep learning (DL) with DenseNet can accurately classify COVID-19 on HRCT with an AUC of 0.98, which can reduce the miss diagnosis rate (combined with radiologists' evaluation) and radiologists' workload.","Ann Transl Med","Yang, Shuyi","Jiang, Longquan","Cao, Zhuoqun","Wang, Liya","Cao, Jiawang","Feng, Rui","Zhang, Zhiyong","Xue, Xiangyang","Shi, Yuxin","Shan, Fei","32395494"],"abstract":["Background: To evaluate the diagnostic efficacy of Densely Connected Convolutional Networks (DenseNet) for detection of COVID-19 features on high resolution computed tomography (HRCT). Methods: The Ethic Committee of our institution approved the protocol of this study and waived the requirement for patient informed consent. Two hundreds and ninety-five patients were enrolled in this study (healthy person: 149; COVID-19 patients: 146), which were divided into three separate non-overlapping cohorts (training set, n=135, healthy person, n=69, patients, n=66; validation set, n=20, healthy person, n=10, patients, n=10; test set, n=140, healthy person, n=70, patients, n=70). The DenseNet was trained and tested to classify the images as having manifestation of COVID-19 or as healthy. A radiologist also blindly evaluated all the test images and rechecked the misdiagnosed cases by DenseNet. Receiver operating characteristic curves (ROC) and areas under the curve (AUCs) were used to assess the model performance. The sensitivity, specificity and accuracy of DenseNet model and radiologist were also calculated. Results: The DenseNet algorithm model yielded an AUC of 0.99 (95% CI: 0.958-1.0) in the validation set and 0.98 (95% CI: 0.972-0.995) in the test set. The threshold value was selected as 0.8, while for validation and test sets, the accuracies were 95% and 92%, the sensitivities were 100% and 97%, the specificities were 90% and 87%, and the F1 values were 95% and 93%, respectively. The sensitivity of radiologist was 94%, the specificity was 96%, while the accuracy was 95%. Conclusions: Deep learning (DL) with DenseNet can accurately classify COVID-19 on HRCT with an AUC of 0.98, which can reduce the miss diagnosis rate (combined with radiologists' evaluation) and radiologists' workload."],"journal":"Ann Transl Med","authors":["Yang, Shuyi","Jiang, Longquan","Cao, Zhuoqun","Wang, Liya","Cao, Jiawang","Feng, Rui","Zhang, Zhiyong","Xue, Xiangyang","Shi, Yuxin","Shan, Fei"],"date":"2020-05-13T11:00:00Z","year":2020,"_id":"32395494","source":"PubMed","week":"202020|May 11 - May 17","doi":"10.21037/atm.2020.03.132","keywords":["covid-19","deep learning (dl)","high resolution computed tomography (hrct)"],"topics":["Diagnosis"],"weight":1,"_version_":1666627828050821120,"score":286.55338},{"pmid":32339081,"title":"AI Augmentation of Radiologist Performance in Distinguishing COVID-19 from Pneumonia of Other Etiology on Chest CT.","text":["AI Augmentation of Radiologist Performance in Distinguishing COVID-19 from Pneumonia of Other Etiology on Chest CT.","Background COVID-19 and pneumonia of other etiology share similar CT characteristics, contributing to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system in differentiating COVID-19 and other pneumonia on chest CT and assess radiologist performance without and with AI assistance. Methods 521 patients with positive RT-PCR for COVID-19 and abnormal chest CT findings were retrospectively identified from ten hospitals from January 2020 to April 2020. 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia on chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by two-layer fully-connected neural network to pool slices together. Our final cohort of 1,186 patients (132,583 CT slices) was divided into training, validation and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance on separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results Our final model achieved a test accuracy of 96% (95% CI: 90-98%), sensitivity 95% (95% CI: 83-100%) and specificity of 96% (95% CI: 88-99%) with Receiver Operating Characteristic (ROC) AUC of 0.95 and Precision-Recall (PR) AUC of 0.90. On independent testing, our model achieved an accuracy of 87% (95% CI: 82-90%), sensitivity of 89% (95% CI: 81-94%) and specificity of 86% (95% CI: 80-90%) with ROC AUC of 0.90 and PR AUC of 0.87. Assisted by the models' probabilities, the radiologists achieved a higher average test accuracy (90% vs. 85%, Delta=5, p<0.001), sensitivity (88% vs. 79%, Delta=9, p<0.001) and specificity (91% vs. 88%, Delta=3, p=0.001). Conclusion AI assistance improved radiologists' performance in distinguishing COVID-19 from non-COVID-19 pneumonia on chest CT.","Radiology","Bai, Harrison X","Wang, Robin","Xiong, Zeng","Hsieh, Ben","Chang, Ken","Halsey, Kasey","Tran, Thi My Linh","Choi, Ji Whae","Wang, Dong-Cui","Shi, Lin-Bo","Mei, Ji","Jiang, Xiao-Long","Pan, Ian","Zeng, Qiu-Hua","Hu, Ping-Feng","Li, Yi-Hui","Fu, Fei-Xian","Huang, Raymond Y","Sebro, Ronnie","Yu, Qi-Zhi","Atalay, Michael K","Liao, Wei-Hua","32339081"],"abstract":["Background COVID-19 and pneumonia of other etiology share similar CT characteristics, contributing to the challenges in differentiating them with high accuracy. Purpose To establish and evaluate an artificial intelligence (AI) system in differentiating COVID-19 and other pneumonia on chest CT and assess radiologist performance without and with AI assistance. Methods 521 patients with positive RT-PCR for COVID-19 and abnormal chest CT findings were retrospectively identified from ten hospitals from January 2020 to April 2020. 665 patients with non-COVID-19 pneumonia and definite evidence of pneumonia on chest CT were retrospectively selected from three hospitals between 2017 and 2019. To classify COVID-19 versus other pneumonia for each patient, abnormal CT slices were input into the EfficientNet B4 deep neural network architecture after lung segmentation, followed by two-layer fully-connected neural network to pool slices together. Our final cohort of 1,186 patients (132,583 CT slices) was divided into training, validation and test sets in a 7:2:1 and equal ratio. Independent testing was performed by evaluating model performance on separate hospitals. Studies were blindly reviewed by six radiologists without and then with AI assistance. Results Our final model achieved a test accuracy of 96% (95% CI: 90-98%), sensitivity 95% (95% CI: 83-100%) and specificity of 96% (95% CI: 88-99%) with Receiver Operating Characteristic (ROC) AUC of 0.95 and Precision-Recall (PR) AUC of 0.90. On independent testing, our model achieved an accuracy of 87% (95% CI: 82-90%), sensitivity of 89% (95% CI: 81-94%) and specificity of 86% (95% CI: 80-90%) with ROC AUC of 0.90 and PR AUC of 0.87. Assisted by the models' probabilities, the radiologists achieved a higher average test accuracy (90% vs. 85%, Delta=5, p<0.001), sensitivity (88% vs. 79%, Delta=9, p<0.001) and specificity (91% vs. 88%, Delta=3, p=0.001). Conclusion AI assistance improved radiologists' performance in distinguishing COVID-19 from non-COVID-19 pneumonia on chest CT."],"journal":"Radiology","authors":["Bai, Harrison X","Wang, Robin","Xiong, Zeng","Hsieh, Ben","Chang, Ken","Halsey, Kasey","Tran, Thi My Linh","Choi, Ji Whae","Wang, Dong-Cui","Shi, Lin-Bo","Mei, Ji","Jiang, Xiao-Long","Pan, Ian","Zeng, Qiu-Hua","Hu, Ping-Feng","Li, Yi-Hui","Fu, Fei-Xian","Huang, Raymond Y","Sebro, Ronnie","Yu, Qi-Zhi","Atalay, Michael K","Liao, Wei-Hua"],"date":"2020-04-28T11:00:00Z","year":2020,"_id":"32339081","source":"PubMed","week":"202018|Apr 27 - May 03","doi":"10.1148/radiol.2020201491","topics":["Diagnosis"],"weight":1,"_version_":1666138494257332224,"score":279.46286},{"pmid":32337662,"pmcid":"PMC7183816","title":"Classification of COVID-19 patients from chest CT images using multi-objective differential evolution-based convolutional neural networks.","text":["Classification of COVID-19 patients from chest CT images using multi-objective differential evolution-based convolutional neural networks.","Early classification of 2019 novel coronavirus disease (COVID-19) is essential for disease cure and control. Compared with reverse-transcription polymerase chain reaction (RT-PCR), chest computed tomography (CT) imaging may be a significantly more trustworthy, useful, and rapid technique to classify and evaluate COVID-19, specifically in the epidemic region. Almost all hospitals have CT imaging machines; therefore, the chest CT images can be utilized for early classification of COVID-19 patients. However, the chest CT-based COVID-19 classification involves a radiology expert and considerable time, which is valuable when COVID-19 infection is growing at rapid rate. Therefore, an automated analysis of chest CT images is desirable to save the medical professionals' precious time. In this paper, a convolutional neural networks (CNN) is used to classify the COVID-19-infected patients as infected (+ve) or not (-ve). Additionally, the initial parameters of CNN are tuned using multi-objective differential evolution (MODE). Extensive experiments are performed by considering the proposed and the competitive machine learning techniques on the chest CT images. Extensive analysis shows that the proposed model can classify the chest CT images at a good accuracy rate.","Eur J Clin Microbiol Infect Dis","Singh, Dilbag","Kumar, Vijay","Vaishali","Kaur, Manjit","32337662"],"abstract":["Early classification of 2019 novel coronavirus disease (COVID-19) is essential for disease cure and control. Compared with reverse-transcription polymerase chain reaction (RT-PCR), chest computed tomography (CT) imaging may be a significantly more trustworthy, useful, and rapid technique to classify and evaluate COVID-19, specifically in the epidemic region. Almost all hospitals have CT imaging machines; therefore, the chest CT images can be utilized for early classification of COVID-19 patients. However, the chest CT-based COVID-19 classification involves a radiology expert and considerable time, which is valuable when COVID-19 infection is growing at rapid rate. Therefore, an automated analysis of chest CT images is desirable to save the medical professionals' precious time. In this paper, a convolutional neural networks (CNN) is used to classify the COVID-19-infected patients as infected (+ve) or not (-ve). Additionally, the initial parameters of CNN are tuned using multi-objective differential evolution (MODE). Extensive experiments are performed by considering the proposed and the competitive machine learning techniques on the chest CT images. Extensive analysis shows that the proposed model can classify the chest CT images at a good accuracy rate."],"journal":"Eur J Clin Microbiol Infect Dis","authors":["Singh, Dilbag","Kumar, Vijay","Vaishali","Kaur, Manjit"],"date":"2020-04-28T11:00:00Z","year":2020,"_id":"32337662","source":"PubMed","week":"202018|Apr 27 - May 03","doi":"10.1007/s10096-020-03901-z","keywords":["chest ct","convolutional neural networks","coronavirus","differential evolution","multi-objective"],"topics":["Diagnosis"],"weight":1,"_version_":1666138494193369089,"score":261.2271}]}